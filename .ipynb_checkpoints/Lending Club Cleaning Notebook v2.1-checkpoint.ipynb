{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lending Club is a \"Market Place Lender\" which allows an individual to apply for a personal loan to be filled by the market, as opposed to a bank or other specialty lender.   They have grown in success and to date have closed over $3Bn in loans.    Lending Club has made loan and performance information freely available on their website. \n",
    "\n",
    "The data is available on the Lending Club website (https://www.lendingclub.com/info/download-data.action).   I manually downloaded the CSV files and stored them locally.   I am using only one subset of the total lending club data.  \n",
    "\n",
    "My objectives in this project are threefold:\n",
    "    i) Learn how to view, clean and manipulate large datasets;\n",
    "    ii)Develop intuition for fitting estimators to the data;\n",
    "    iii) What are the best predictors of borrower default? \n",
    "    iv) What rates do borrowers pay versus their other financial options?\n",
    "    v) What are the best predictors of early borrower repayment? \n",
    "    vi) Start to develop a better way to predict creditworthiness of borrowers beyond the standard methods (eg, FICO); \n",
    "        a) For example, can we parse their loan purpose comments to develop a predictor of default?\n",
    "        b) Can I take location information (eg, via zip codes) to get a better understanding the regional economy? \n",
    "        c) Ultimately, I would like to also use complementary external data sources to allow better prediction. \n",
    "\n",
    "## AS OF THE END DATE OF THE COURSE:  \n",
    "A lot of time has been spent on cleaning, scrubbing, and understanding the organization of the data.   I had to generate some calculated features, and further projects include parsing the text fields.   \n",
    "\n",
    "\n",
    " ### This spreadsheet will be modified to do the file cleaning, with analysis and visualisation in separate notebook. \n",
    " I will take the 4 Lending Club CSV files to see if they can be 'stitched' together for processing. \n",
    " \n",
    " 22 June 15 - Added file write and append logic.   Features selected for write operation to be consistent with merge\n",
    " 31 July 15 - Attemping to merge all feature engineering and cleaning into this spradsheet.  Added 'days to default' feature.   Subsequent (separate) notebooks will do graphing and analysis.   \n",
    " \n",
    " 05 Aug - Broke up notebook into three separate notebooks:\n",
    "     i) File opening, cleaning, and appending (THIS ONE)\n",
    "     ii) Graphs\n",
    "     iii) Stats\n",
    "     \n",
    "The graph and stats notebooks work off the same file created here (currently named Lending_Club_CLEANED_V2.csv).  Some Jiggery Pokery required as LC files from 07-12 have slightly different file structure than later versions.   CUrrently no logic to handle this, as I manually comment/uncomment relevant fields.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load relevant libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#import dataset\n",
    "# Also, check why if header = 1 is used we seem to propogate NaN.\n",
    "# Check file integrity of original file - noted gaps in the file used, manually correct. \n",
    "\n",
    "# url = \"/Users/Glenn/Documents/LendingClub/LendingClub_07-12_Approved.csv\"\n",
    "# url = \"/Users/Glenn/Documents/LendingClub/LendingClub_2015_Q1.csv\"\n",
    "#  \n",
    "#                              iii) LendingClub_2014_Approved.csv\n",
    "\n",
    "# url = \"/Users/Glenn/Documents/LendingClub/LendingClub_12-13.csv\"\n",
    "# url = \"/Users/Glenn/Documents/LendingClub/LendingClub_13-14.csv\"\n",
    "# url = \"/Users/Glenn/Documents/LendingClub/LendingClub_07-12_Approved_29MAY.csv\"\n",
    "## THESE ARE MOST RECENT URLs FROM AUG 03 LC DOWNLOAD...\n",
    "\n",
    "# url = \"/Users/Glenn/Documents/LendingClub/Data/03AUG15/LC_Data_07-12_03AUG15.csv\"\n",
    "# url = \"/Users/Glenn/Documents/LendingClub/Data/03AUG15/LC_Data_12-13_03AUG15.csv\"\n",
    "# url = \"/Users/Glenn/Documents/LendingClub/Data/03AUG15/LC_Data_13-14_03AUG15.csv\"\n",
    "url = \"/Users/Glenn/Documents/LendingClub/Data/03AUG15/LC_Data_15_03AUG15.csv\"\n",
    "\n",
    "lcd_raw = pd.read_csv(url,skiprows=1,\n",
    "            parse_dates=['last_pymnt_d','issue_d','last_credit_pull_d','last_pymnt_d','next_pymnt_d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>last_pymnt_d</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>next_pymnt_d</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>last_fico_range_high</th>\n",
       "      <th>last_fico_range_low</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <th>policy_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84274</th>\n",
       "      <td>                                         36271333</td>\n",
       "      <td> 38982739</td>\n",
       "      <td> 13000</td>\n",
       "      <td> 13000</td>\n",
       "      <td> 13000</td>\n",
       "      <td>  60 months</td>\n",
       "      <td>  15.99%</td>\n",
       "      <td> 316.07</td>\n",
       "      <td>   D</td>\n",
       "      <td>  D2</td>\n",
       "      <td>...</td>\n",
       "      <td>  0</td>\n",
       "      <td>2015-07-12</td>\n",
       "      <td> 316.07</td>\n",
       "      <td>2015-09-12</td>\n",
       "      <td>2015-07-12</td>\n",
       "      <td> 684</td>\n",
       "      <td> 680</td>\n",
       "      <td>  0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>  1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84275</th>\n",
       "      <td>                                         36490806</td>\n",
       "      <td> 39222577</td>\n",
       "      <td> 12000</td>\n",
       "      <td> 12000</td>\n",
       "      <td> 12000</td>\n",
       "      <td>  60 months</td>\n",
       "      <td>  19.99%</td>\n",
       "      <td> 317.86</td>\n",
       "      <td>   E</td>\n",
       "      <td>  E3</td>\n",
       "      <td>...</td>\n",
       "      <td>  0</td>\n",
       "      <td>2015-07-12</td>\n",
       "      <td> 317.86</td>\n",
       "      <td>2015-09-12</td>\n",
       "      <td>2015-07-12</td>\n",
       "      <td> 694</td>\n",
       "      <td> 690</td>\n",
       "      <td>  1</td>\n",
       "      <td> 22</td>\n",
       "      <td>  1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84276</th>\n",
       "      <td>                                         36271262</td>\n",
       "      <td> 38982659</td>\n",
       "      <td> 20000</td>\n",
       "      <td> 20000</td>\n",
       "      <td> 20000</td>\n",
       "      <td>  36 months</td>\n",
       "      <td>  11.99%</td>\n",
       "      <td> 664.20</td>\n",
       "      <td>   B</td>\n",
       "      <td>  B5</td>\n",
       "      <td>...</td>\n",
       "      <td>  0</td>\n",
       "      <td>2015-07-12</td>\n",
       "      <td> 664.20</td>\n",
       "      <td>2015-09-12</td>\n",
       "      <td>2015-07-12</td>\n",
       "      <td> 649</td>\n",
       "      <td> 645</td>\n",
       "      <td>  0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>  1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84277</th>\n",
       "      <td> Total amount funded in policy code 1: 1290044375</td>\n",
       "      <td>      NaN</td>\n",
       "      <td>   NaN</td>\n",
       "      <td>   NaN</td>\n",
       "      <td>   NaN</td>\n",
       "      <td>        NaN</td>\n",
       "      <td>     NaN</td>\n",
       "      <td>    NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>       NaT</td>\n",
       "      <td>    NaN</td>\n",
       "      <td>       NaT</td>\n",
       "      <td>       NaT</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84278</th>\n",
       "      <td>  Total amount funded in policy code 2: 345045816</td>\n",
       "      <td>      NaN</td>\n",
       "      <td>   NaN</td>\n",
       "      <td>   NaN</td>\n",
       "      <td>   NaN</td>\n",
       "      <td>        NaN</td>\n",
       "      <td>     NaN</td>\n",
       "      <td>    NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>       NaT</td>\n",
       "      <td>    NaN</td>\n",
       "      <td>       NaT</td>\n",
       "      <td>       NaT</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id  member_id  loan_amnt  \\\n",
       "84274                                          36271333   38982739      13000   \n",
       "84275                                          36490806   39222577      12000   \n",
       "84276                                          36271262   38982659      20000   \n",
       "84277  Total amount funded in policy code 1: 1290044375        NaN        NaN   \n",
       "84278   Total amount funded in policy code 2: 345045816        NaN        NaN   \n",
       "\n",
       "       funded_amnt  funded_amnt_inv        term int_rate  installment grade  \\\n",
       "84274        13000            13000   60 months   15.99%       316.07     D   \n",
       "84275        12000            12000   60 months   19.99%       317.86     E   \n",
       "84276        20000            20000   36 months   11.99%       664.20     B   \n",
       "84277          NaN              NaN         NaN      NaN          NaN   NaN   \n",
       "84278          NaN              NaN         NaN      NaN          NaN   NaN   \n",
       "\n",
       "      sub_grade     ...     collection_recovery_fee last_pymnt_d  \\\n",
       "84274        D2     ...                           0   2015-07-12   \n",
       "84275        E3     ...                           0   2015-07-12   \n",
       "84276        B5     ...                           0   2015-07-12   \n",
       "84277       NaN     ...                         NaN          NaT   \n",
       "84278       NaN     ...                         NaN          NaT   \n",
       "\n",
       "      last_pymnt_amnt  next_pymnt_d last_credit_pull_d last_fico_range_high  \\\n",
       "84274          316.07    2015-09-12         2015-07-12                  684   \n",
       "84275          317.86    2015-09-12         2015-07-12                  694   \n",
       "84276          664.20    2015-09-12         2015-07-12                  649   \n",
       "84277             NaN           NaT                NaT                  NaN   \n",
       "84278             NaN           NaT                NaT                  NaN   \n",
       "\n",
       "      last_fico_range_low collections_12_mths_ex_med  \\\n",
       "84274                 680                          0   \n",
       "84275                 690                          1   \n",
       "84276                 645                          0   \n",
       "84277                 NaN                        NaN   \n",
       "84278                 NaN                        NaN   \n",
       "\n",
       "      mths_since_last_major_derog policy_code  \n",
       "84274                         NaN           1  \n",
       "84275                          22           1  \n",
       "84276                         NaN           1  \n",
       "84277                         NaN         NaN  \n",
       "84278                         NaN         NaN  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcd_raw.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean bottom of file and create new dataframe from it\n",
    "lcd = lcd_raw[:-2].copy()\n",
    "\n",
    "# Create Datetime fields from date information....\n",
    "# lcd = lcd.drop(lcd.index[lcd.last_pymnt_d == 'nan'])\n",
    "lcd['last_pymnt_date'] = [pd.to_datetime(j, format='%b-%Y', unit = \"D\") for j in lcd.last_pymnt_d]\n",
    "lcd['next_pymnt_date'] = [pd.to_datetime(j,format='%b-%Y', unit = \"D\") for j in lcd.next_pymnt_d]\n",
    "lcd['last_credit_pull_date'] = [pd.to_datetime(j, unit = \"D\",format='%b-%Y') for j in lcd.last_credit_pull_d]\n",
    "lcd['issue_date'] = [pd.to_datetime(j, format='%b-%Y', unit = \"D\") for j in lcd.issue_d]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lcd = lcd[pd.notnull(lcd.loan_amnt) & pd.notnull(lcd.last_pymnt_d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                 0\n",
       "member_id                          0\n",
       "loan_amnt                          0\n",
       "funded_amnt                        0\n",
       "funded_amnt_inv                    0\n",
       "term                               0\n",
       "int_rate                           0\n",
       "installment                        0\n",
       "grade                              0\n",
       "sub_grade                          0\n",
       "emp_title                       4643\n",
       "emp_length                         0\n",
       "home_ownership                     0\n",
       "annual_inc                         0\n",
       "verification_status                0\n",
       "issue_d                            0\n",
       "loan_status                        0\n",
       "pymnt_plan                         0\n",
       "url                                0\n",
       "desc                           84216\n",
       "purpose                            0\n",
       "title                              0\n",
       "zip_code                           0\n",
       "addr_state                         0\n",
       "dti                                0\n",
       "delinq_2yrs                        0\n",
       "earliest_cr_line                   0\n",
       "fico_range_low                     0\n",
       "fico_range_high                    0\n",
       "inq_last_6mths                     0\n",
       "mths_since_last_delinq         40827\n",
       "mths_since_last_record         69640\n",
       "open_acc                           0\n",
       "pub_rec                            0\n",
       "revol_bal                          0\n",
       "revol_util                        33\n",
       "total_acc                          0\n",
       "initial_list_status                0\n",
       "out_prncp                          0\n",
       "out_prncp_inv                      0\n",
       "total_pymnt                        0\n",
       "total_pymnt_inv                    0\n",
       "total_rec_prncp                    0\n",
       "total_rec_int                      0\n",
       "total_rec_late_fee                 0\n",
       "recoveries                         0\n",
       "collection_recovery_fee            0\n",
       "last_pymnt_d                       0\n",
       "last_pymnt_amnt                    0\n",
       "next_pymnt_d                    3931\n",
       "last_credit_pull_d                 4\n",
       "last_fico_range_high               0\n",
       "last_fico_range_low                0\n",
       "collections_12_mths_ex_med         0\n",
       "mths_since_last_major_derog    59952\n",
       "policy_code                        0\n",
       "last_pymnt_date                    0\n",
       "next_pymnt_date                 3931\n",
       "last_credit_pull_date              4\n",
       "issue_date                         0\n",
       "Length: 60, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcd.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Substitute \"No Response\" for any #NA in title, desc, emp_title features\n",
    "lcd.title.fillna(value = \"No response\",inplace = True)\n",
    "lcd.desc.fillna(value=\"No response\", inplace = True)\n",
    "lcd.emp_title.fillna(value=\"No response\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace all Nan's for 'mnths_since_last_delinq',  with 999....this is a kludge for now.  If this feature is used in logistic\n",
    "# Regression, we'll want to make sure its far away from the other real delinquencies...\n",
    "lcd['mths_since_last_delinq'].fillna(value=999, inplace=True)\n",
    "lcd['mths_since_last_record'].fillna(value=999,inplace=True)\n",
    "lcd['mths_since_last_major_derog'].fillna(value=999,inplace = True)\n",
    "# lcd['mths_since_last_delinq'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Convert Field Employment Length into a numeric...\n",
    "#lcd.emp_length.unique()\n",
    "#array(['10+ years', , '1 year', '3 years', '8 years', '9 years',\n",
    "#        '4 years', '5 years', '6 years', '2 years', '7 years', 'n/a'], dtype=object)\n",
    "\n",
    "lcd['emp_length_numeric'] = lcd['emp_length'].map({'< 1 year':0, '1 year':1, '2 years':2, '3 years':3, \n",
    "                                                  '4 years':4,'5 years':5,'6 years':6,'7 years':7,\n",
    "                                                  '8 years':8,'9 years':9,'10+ years':10})\n",
    "\n",
    "# Now graph\n",
    "# lcd['emp_length_numeric'].hist()\n",
    "# plt.title('Employment Length counts')\n",
    "# plt.xlabel('Employment Length (yrs)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Employment length reasonably evenly distributed out to 5 years.    How is this distributed versus FICO score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x113c4b150>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAYcAAAECCAYAAAAVYxsVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAFIpJREFUeJzt3X+MXeV95/H3JXiMHcYjFJl4k1adjbJ8iyKxKBST8NOo\n",
       "BApKxNaRkiZtQ2kCCaEolaolxaIhTtklq5Q0Rc06Fd6GIGj/CPJm0yIMCaVrM2nilCS0qOnXZRNX\n",
       "SlXjwMbjIf5t3/5xj8swz3h8z5175947835JR5557nnmPOe5Z+bjc55znttoNptIkjTdaf1ugCRp\n",
       "8BgOkqSC4SBJKhgOkqSC4SBJKhgOkqTC6adaISIuAj6dmVdGxPnAfcAx4BDwgczcExE3ATcDR4G7\n",
       "M/PRiFgBPASsBqaAGzLzxYh4G/C5at0nMvNTPdkzSVLH5jxziIjbgfuB5VXR54DfyswrgS3AxyPi\n",
       "9cBtwMXANcA9ETEC3AI8m5mXAw8Cd1Y/4wvA+zLzUuCiKnAkSQPkVJeVngfWA43q+1/JzL+rvl4G\n",
       "HADWAhOZeSQz91V1zgMuAbZW624FroqIUWAkM39YlT8OXNWVPZEkdc2c4ZCZW2hd/jnx/W6AiLgY\n",
       "uBX4Q2AVMDmt2hQwVpXvm6NserkkaYDUHpCOiPcCm4DrMvMlWn/sR6etMgrsnVE+Wxm0wmJv/WZL\n",
       "knrplAPS00XEr9EaeF6XmT+pincA/y0ilgNnAOcCzwETwHXAt4FrgW2ZORURhyPiTcAPgauBT7ax\n",
       "6YO8Mu4hSTq1xqlXObl2w6EZEacBfwT8M7AlIgD+OjM3RsR9wHZaZyIbMvNQRGwCvhQR22nd2fT+\n",
       "6md9BHgYeA3weGZ+u43tL2eeO7qINLEvTrAvWuyHV9gXXdIYkllZfcNfYV+8wr5osR9eYV90iQ/B\n",
       "SZIKhoMkqWA4SJIKhoMkqWA4SJIKhoMkqWA4SJIKhoMkqWA4SJIKhoMkqWA4SJIKhoMkqWA4SJIK\n",
       "hoMkqWA4SJIKhoMkqWA4SJIKhoMkqWA4SJIKhoMkqWA4SJIKhoMkqWA4SJIKhoMkqWA4SJIKhoMk\n",
       "qWA4SJIKp/e7ARo8jUZjBBjvoOquZrN5uMvNkdQHhoNmM752/V25cuzstivsn9zDji0bA9jZu2ZJ\n",
       "WiinDIeIuAj4dGZeGRFvBh4AjgPPAbdmZjMibgJuBo4Cd2fmoxGxAngIWA1MATdk5osR8Tbgc9W6\n",
       "T2Tmp3qxY5qflWNnc+ZZb+x3MyT1yZxjDhFxO3A/sLwq+iywITMvBxrA9RGxBrgNuBi4BrgnIkaA\n",
       "W4Bnq3UfBO6sfsYXgPdl5qXARRFxfpf3SZI0T6cakH4eWE8rCADempnbqq8fA64CLgQmMvNIZu6r\n",
       "6pwHXAJsrdbdClwVEaPASGb+sCp/vPoZkqQBMmc4ZOYWWpd/TmhM+3oKGANWAZMnKd83R9n0cknS\n",
       "AKl7K+vxaV+vAvbS+mM/Oq18dJby2cqm/wxJ0gCpGw7fjYgrqq+vBbYBO4DLImJ5RIwB59IarJ4A\n",
       "rpu+bmZOAYcj4k0R0QCurn5GO5ouNBeiLzIz23pHZqjqLaq+GJLFfrAvTtYXHWs3HE5s6HeAjRHx\n",
       "DVp3Oj2SmS8A9wHbgSdpDVgfAjYBb4mI7cCHgI3Vz/gI8DDwLeA7mfntNtvQcPn3y3o93UZERFvv\n",
       "yAxVvUXVF0Oy2A/2xcn6omONZnPeAbMQmnRhZxeJnvdFo9E4Z92Nn886t7K+/JN/4a+/eGs0m82F\n",
       "fM7B46LFfniFfdElTp8hSSoYDpKkguEgSSoYDpKkguEgSSoYDpKkguEgSSoYDpKkguEgSSoYDpKk\n",
       "guEgSSoYDpKkguEgSSoYDpKkguEgSSoYDpKkguEgSSoYDpKkguEgSSoYDpKkguEgSSoYDpKkguEg\n",
       "SSoYDpKkguEgSSoYDpKkguEgSSoYDpKkguEgSSoYDpKkwul1K0TEacBm4BzgOHATcAx4oPr+OeDW\n",
       "zGxGxE3AzcBR4O7MfDQiVgAPAauBKeCGzHyxC/siSeqSTs4crgZem5mXAp8C/jtwL7AhMy8HGsD1\n",
       "EbEGuA24GLgGuCciRoBbgGerdR8E7pz/bkiSuqmTcDgAjEVEAxgDDgMXZOa26vXHgKuAC4GJzDyS\n",
       "mfuA54HzgEuArdW6W6t1JUkDpPZlJWACOAP4R+B1wLuAy6e9PkUrNFYBkycp3zejTJI0QDo5c7id\n",
       "1hlBAOfTujS0bNrrq4C9tAJgdFr56CzlJ8ra0XShuRB9kZnZ1jsyQ1VvUfXFkCz2g31xsr7oWCfh\n",
       "8Fpe+Z//T2idfXw3Iq6oyq4FtgE7gMsiYnlEjAHn0hqsngCum7FuOxouNBaiLyIi2npHZqjqLaq+\n",
       "GJLFfrAvTtYXHevkstJngC9GxHZaZwx3AM8A91cDzv8APFLdrXQfsJ1WCG3IzEMRsQn4UlX/EPD+\n",
       "+e6EJKm7aodDZu4FfnmWl9bNsu5mWre9Ti87ALyn7nYlSQvHh+AkSQXDQZJUMBwkSYVOBqSlwvFj\n",
       "RwHGG42ObpLY1Ww2D3e3RZLmw3BQVxx8+SXWrr/r8ZVjZ9eqt39yDzu2bAxgZ29aJqkThoO6ZuXY\n",
       "2Zx51hv73QxJXeCYgySp4JnDItZoNEaA8Q6qdlJH0iJiOCxu42vX35V1xwFe+tH3e9QcScPCcFjk\n",
       "OhkH2D/5Qo9aI2lYGA4aOicul2UmEXFOzereNiu1wXDQMBpfu/6u/PCnv866Gz/f9vTi3jYrtc9w\n",
       "0FDytlmpt7yVVZJUMBwkSQXDQZJUMBwkSQXDQZJUWHR3KzUajRWvf9OFHz3t9JFmnXpHD+3/wZ5d\n",
       "3/lKr9olScNk0YUDsOrNa9/9ybPe8PNn1qn0g2f+zxbAcJAkFmc4aIh0+CFB4z1pjKR/Zziorzr5\n",
       "kCAnBpR6z3BQ39V92tmJAaXe824lSVLBcJAkFQwHSVLBcJAkFRyQnod5fEazHzgjaaAZDvNT+zOa\n",
       "/cAZScOgo3CIiDuAdwHLgD8GJoAHgOPAc8CtmdmMiJuAm4GjwN2Z+WhErAAeAlYDU8ANmfnifHek\n",
       "X/zQGUmLUe0xh4hYB7w9My8G1gFvAu4FNmTm5UADuD4i1gC3ARcD1wD3RMQIcAvwbLXug8CdXdgP\n",
       "SVIXdTIgfTXw9xHxFeAvgK8CF2Tmtur1x4CrgAuBicw8kpn7gOeB84BLgK3VulurdSVJA6STy0qr\n",
       "gZ8F3knrrOEvaJ0tnDAFjAGrgMmTlO+bUSZJGiCdnDm8CDyRmUczcydwkFf/gV8F7KUVAKPTykdn\n",
       "KT9R1o5mO8vu3bt3rzhjWa0ZWQGuuuyC9e1u48SSmVl3OwBVvVrbmrbQ6/YtZvPs+0FdGIA2DMpi\n",
       "X7y6LzrWSTg8DfwSQES8AVgJPBkRV1SvXwtsA3YAl0XE8ogYA86lNVg9AVw3Y912NNpZ1qxZs+bA\n",
       "wSMv192pr29/Zku72zixRETU3Q5AVa/WtqYt9Lp9i9k8+35QFwagDYOy2Bev7ouO1b6sVN1xdHlE\n",
       "7KAVLh8FdgH3VwPO/wA8Ut2tdB+wvVpvQ2YeiohNwJciYjtwCHj/fHdCktRdHd3Kmpkfn6V43Szr\n",
       "bQY2zyg7ALynk+1KkhaG02dIkgqGgySpYDhIkgqGgySpYDhIkgrOylo5fuxoo9FonFOz2ngv2iJJ\n",
       "/WY4VA7t3/vautNvv/Sj7/ewRZLUP4bDNHWn394/+UIPWyNJ/eOYgySpYDhIkgqGgySpYDhIkgqG\n",
       "gySpYDhIkgqGgySpYDhIkgqGgySpYDhIkgqGgySpYDhIkgpOvCfNodFojND51Oy7ms3m4S42R1ow\n",
       "hoM0t/G6U7kD7J/cw44tGwPY2ZtmSb1lOAyJE/+DzUwiot0PJRrvYZOWjLpTuUuLgeEwPMbXrr8r\n",
       "P/zpr7Puxs9nOxX8MCJJnTIchogfRiRpoXi3kiSpYDhIkgqGgySpYDhIkgodD0hHxNnAM8AvAseB\n",
       "B6p/nwNuzcxmRNwE3AwcBe7OzEcjYgXwELAamAJuyMwX57UXkqSu6igcImIZ8CfAT4EG8FlgQ2Zu\n",
       "i4hNwPUR8U3gNuACYAXwdER8DbgFeDYzPxUR7wXuBH57/rsyHI4fOwow3mg06lYd73pjJOkkOj1z\n",
       "+AywCbij+v6tmbmt+vox4GrgGDCRmUeAIxHxPHAecAnwP6p1twK/12EbhtLBl19i7fq7Hq/7xK3P\n",
       "LEhaSLXDISJ+A/hxZj4REXfQOnOY/t/gKWAMWAVMnqR834yyJaWTJ259ZkHSQupkQPpG4B0R8RRw\n",
       "PvAlWuMHJ6wC9tIKgNFp5aOzlJ8oa0eznWX37t27V5yx7My6O3XpRedfXbeOhk9mJm0eS0CzWn9B\n",
       "tjWPhQXazjAs9sWr+6JjtcMhM6/IzHWZeSXwPeADwNaIuKJa5VpgG7ADuCwilkfEGHAurcHqCeC6\n",
       "Geu2o9HOsmbNmjUHDh55ue5+Pf2t7z1Rt46GT0QEbR5LQKNaf0G2NY+FBdrOMCz2xav7omPduJW1\n",
       "CfwOsDEivkHrUtUjmfkCcB+wHXiS1oD1IVpjFW+JiO3Ah4CNXWiDJKmL5jW3UnX2cMK6WV7fDGye\n",
       "UXYAeM98tit1osM7xcZ70hhpwDnxnpaMTu4U8y4xLVWGg5YUZ7aV2uP0GZKkguEgSSoYDpKkguEg\n",
       "SSoYDpKkguEgSSoYDpKkguEgSSoYDpKkguEgSSoYDpKkguEgSSoYDpKkguEgSSoYDpKkguEgSSoY\n",
       "DpKkgp8EJ/VAh59XDbCr2Wwe7n6LpHoMB6kHOvm86v2Te9ixZWMAO3vXMqk9hoPUI3U/r1oaJI45\n",
       "SJIKhoMkqWA4SJIKhoMkqWA4SJIK3q0kDYhOn43ITCJixOcj1E2GgzQgOnk2AuDX7/gzgHF8PkJd\n",
       "VDscImIZ8KfAzwHLgbuB7wMPAMeB54BbM7MZETcBNwNHgbsz89GIWAE8BKwGpoAbMvPFLuyLNPR8\n",
       "NkKDopMxh18FfpyZlwO/BHweuBfYUJU1gOsjYg1wG3AxcA1wT0SMALcAz1brPgjcOf/dkCR1Uyfh\n",
       "8GXgE9PqHwHempnbqrLHgKuAC4GJzDySmfuA54HzgEuArdW6W6t1JUkDpPZlpcz8KUBEjNIKijuB\n",
       "P5i2yhQwBqwCJk9Svm9GmSRpgHR0K2tE/CzwV8CDmfnntMYaTlgF7KUVAKPTykdnKT9RJkkaILXD\n",
       "ISJeDzwB3J6ZD1TF342IK6qvrwW2ATuAyyJieUSMAefSGqyeAK6bsW47mu0su3fv3r3ijGVn1t2v\n",
       "Sy86/+q6daRBkZlJm78ji3xhANowKMu8dHLmsIHWpaBPRMRTEfEUrUtLGyPiG7QuVT2SmS8A9wHb\n",
       "gSdpDVgfAjYBb4mI7cCHgI1tbrfRzrJmzZo1Bw4eebnuTj39re89UbeONCgiImjzd2SRLwxAGwZl\n",
       "mZdOxhw+BnxslpfWzbLuZmDzjLIDwHvqbleStHCcPkOSVDAcJEkFw0GSVDAcJEkFw0GSVDAcJEkF\n",
       "w0GSVDAcJEkFw0GSVDAcJEkFw0GSVDAcJEmF2hPvSRosx48dBRhvNGpPxLmr2Wwe7n6LtBgYDtKQ\n",
       "O/jyS6xdf9fjK8fObrvO/sk97NiyMYCdvWuZhpnhIC0CK8fO5syz3tjvZmgRccxBklTwzEFaguYx\n",
       "TgGOVSwJhoO0BHUyTgGOVSwlhoO0RDlOobkYDpIWjcOHD7N8+fJzOqzu5bJpDAdJi8auXbtYu/6u\n",
       "9HLZ/BkOktq2kA/cNRqNEWC8Tp2tW7d6uaxLDAdJbVvgB+7G654F/Nd7/5LX/cy5NTej2RgOkmpZ\n",
       "yP+Z193W/skXetiapcWH4CRJBc8cJPXUPMYpxrveGLXNcJDUU50+cPfSj77foxapHYaDpJ7rZJzC\n",
       "8YP+csxBklToy5lDRJwG/E/gPOAQ8KHM/H/9aIskqdSvM4f/Aoxk5sXA7wL39qkdkqRZ9CscLgG2\n",
       "AmTmt4Bf6FM7JEmz6Fc4rAL2Tfv+WHWpSZI0APp1t9I+YHTa96dl5vEu/ezmnh8+88L+fXtq3erw\n",
       "0727j+6f3FNrQwem/j9Q797tTuq4Lbfltnq7rbq/+0tBv8JhAngX8OWIeBvwd6dYv+13u9ls7gHe\n",
       "PI+2SVqSPtnvBgyUfoXD/wbeERET1fc39qkdkqRZNJrNZr/bIEkaMA4CS5IKhoMkqWA4SJIKhoMk\n",
       "qdDXWVlPNcdSRLwL+D3gKPCnmbm5Kv8OMFmt9oPM/OCCNrwH2plvKiJWAl8DfjMzc7HOUdVJX1Rl\n",
       "S+64iIj3AR+j9Tvy98BHad36veSOi9n6IjObS/S4eDfwcaAJPJyZ99X9e9HvM4eTzrEUEcuAzwLv\n",
       "AK4Abo6I1RFxBkBmXlktQ/9GV+acbyoifgHYBvxHWm/4KesMsdp9sRSPi4hYAfw+sC4zLwXGgHdW\n",
       "dZYvpePiZH2xRI+L1wD3AL8IvB34aES8jprHRb/DYa45ls4Fns/Mycw8AjxNKyT+M7AyIh6PiCcj\n",
       "4qKFbnSPnGq+qRFab27WqDOsOumLpXhcHATenpkHq+9Pr8ouAR47SZ1hVrcvDrAEj4vMPAb8fGZO\n",
       "AauB1wCHqXlc9Dsc5ppjaRWvnAoCTNH638BPgc9k5jXAR4CHF8m8THPON5WZ38jMH9WpM8Q66Ysl\n",
       "d1xkZjMzfwwQEbcBr83Mr81VZ8jV7YuvswSPC4DMPB4R64HvAk/R6odax0W/O2muOZYmZ7w2CvwE\n",
       "2Ak8DJCZ/wS8BPyH3je15zqZb6qXc1T1Uyf7tSSPi4g4LSL+gNYlhHe3U2eIddIXS/K4AMjMLcAb\n",
       "geXAB9qpM12/w2ECuA5gljmW/hH4TxFxVkSMAJcDf0Nrqo17qzpvoJWG/7qQje6Rufqim3WGQSf7\n",
       "tVSPiz+h9cv/y9MuqSzV42K2vlhyx0VErIqI/xsRI5nZpHXWcGyuOrPp6/QZETH9rgpovZEXAGdm\n",
       "5v0R8U7gE7RC7H9l5qaIOB34IvBzVZ3bM/ObC9z0rjtVX0xb7yngw5m5c7Y6mblzAZvdEx32xZI7\n",
       "LoC/rZZt06p8DvjqzDqL/bjg5H3xKEvsuKj+dt4EfBA4AjwL3Fat1/Zx4dxKkqRCvy8rSZIGkOEg\n",
       "SSoYDpKkguEgSSoYDpKkguEgSSoYDpKkguEgSSr8GyjLtTHZbNRmAAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112562790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Strip chars, convert int_rate series to float\n",
    "lcd.int_rate.fillna(method='backfill',inplace = True)\n",
    "lcd['clean_rate'] = [float(t.strip(' %'))/100 for t in lcd.int_rate]\n",
    "\n",
    "# Now graph!\n",
    "lcd['clean_rate'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean term by splitting on spaces and converting numbers into float\n",
    "lcd.term.fillna(method='backfill',inplace = True)\n",
    "lcd['clean_term'] = [float (s.split(' ')[1]) for s in lcd.term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate time to default, assumes we will flag the correct values through state variable\n",
    "\n",
    "lcd = lcd[pd.notnull(lcd.last_pymnt_date) & pd.notnull(lcd.issue_date)]\n",
    "lcd['time_to_default'] = lcd['last_pymnt_date'] - lcd['issue_date']\n",
    "lcd['time_to_default'] = [j.days for j in lcd.time_to_default]\n",
    "lcd['mos_to_default'] = [round(float(j/30),0) for j in lcd.time_to_default]\n",
    "\n",
    "# Create normalized mos to default. \n",
    "lcd['mos_to_default_norm'] = lcd['mos_to_default']/lcd['clean_term']\n",
    "lcd['mos_to_default_norm'] = [min(i,1) for i in lcd.mos_to_default_norm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Sub Grade map \n",
    "# print lcd['sub_grade'].unique()\n",
    "#['B2' 'C4' 'C5' 'C1' 'B5' 'A4' 'E1' 'F2' 'C3' 'B1' 'D1' 'A1' 'B3' 'B4' 'C2'\n",
    "# 'D2' 'A3' 'A5' 'D5' 'A2' 'E4' 'D3' 'D4' 'F3' 'E3' 'F4' 'F1' 'E5' 'G4' 'E2'\n",
    "# 'G3' 'G2' 'G1' 'F5' 'G5']\n",
    "\n",
    "lcd['sub_grade_int']=lcd['sub_grade'].map({'A1':0,'A2':1,'A3':2,'A4':3,'A5':4,\n",
    "                                           'B1':5,'B2':6,'B3':7,'B4':8,'B5':9,\n",
    "                                           'C1':10,'C2':11,'C3':12,'C4':13,'C5':14,\n",
    "                                           'D1':15,'D2':16,'D3':17,'D4':18,'D5':19,\n",
    "                                           'E1':20,'E2':21,'E3':22,'E4':23,'E5':24,\n",
    "                                           'F1':25,'F2':26,'F3':27,'F4':28,'F5':29,\n",
    "                                           'G1':30,'G2':31,'G3':32,'G4':33,'G5':34})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Categorical Variable from LC grades\n",
    "lcd['grade_int']=lcd['grade'].map({'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  THIS IS A KLUDGE TO GET RID OF NAs BY USING BACKFILL....\n",
    "\n",
    "lcd['grade_int'].fillna(method = 'backfill',inplace = True)\n",
    "lcd['sub_grade_int'].fillna(method='backfill',inplace=True)\n",
    "lcd['purpose'].fillna(method = 'backfill',inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use One Hot Encoder to turn Grade, Grade_Int into categorical variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "encoded_grade_status = ohe.fit_transform(lcd[['grade_int']])\n",
    "\n",
    "# Convert to dataframe and add to lcd\n",
    "grade_status_columns = ('A','B','C','D','E','F','G')\n",
    "grade_status_encoded_dataframe = pd.DataFrame(encoded_grade_status, columns=grade_status_columns)\n",
    "\n",
    "# Add to lcd dataframe at end so we avoid problems with re-running cells\n",
    "\n",
    "# Now do the same for subgrade.   \n",
    "encoded_sub_grade_status = ohe.fit_transform(lcd[['sub_grade_int']])\n",
    "sub_grade_status_columns = ('A1','A2','A3','A4','A5',\n",
    "                            'B1','B2','B3','B4','B5',\n",
    "                            'C1','C2','C3','C4','C5',\n",
    "                            'D1','D2','D3','D4','D5',\n",
    "                            'E1','E2','E3','E4','E5',\n",
    "                            'F1','F2','F3','F4','F5',\n",
    "                            'G1','G2','G3','G4','G5')\n",
    "sub_grade_status_encoded_dataframe = pd.DataFrame(encoded_sub_grade_status, columns=sub_grade_status_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['car', 'debt_consolidation', 'credit_card', 'home_improvement',\n",
       "       'small_business', 'other', 'vacation', 'moving', 'medical',\n",
       "       'major_purchase', 'renewable_energy', 'house', 'wedding'], dtype=object)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcd.purpose.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use One Hot Encoder to turn Grade, Grade_Int into categorical variables\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "lcd.purpose.unique()\n",
    "\n",
    "'''\n",
    "# This is for 07-12 File.  \"Education\" Purpose removed in subsequent files.\n",
    "lcd['purpose_int']= lcd['purpose'].map({'credit_card':0, 'car':2, 'small_business':3, 'other':4, \n",
    "                                        'wedding':5,'debt_consolidation':6, 'home_improvement':7, \n",
    "                                        'major_purchase':8, 'medical':9, 'moving':10, 'vacation':11, \n",
    "                                        'house':12, 'renewable_energy':13,'educational':14})\n",
    "'''\n",
    "\n",
    "lcd['purpose_int']= lcd['purpose'].map({'credit_card':0, 'car':2, 'small_business':3, 'other':4, \n",
    "                                        'wedding':5,'debt_consolidation':6, 'home_improvement':7, \n",
    "                                        'major_purchase':8, 'medical':9, 'moving':10, 'vacation':11, \n",
    "                                        'house':12, 'renewable_energy':13})\n",
    "\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "encoded_purpose = ohe.fit_transform(lcd[['purpose_int']])\n",
    "\n",
    "'''\n",
    "# See above comments for 07-12 file \n",
    "purpose_columns = ('PURP:credit_card', 'PURP:car', 'PURP:small_business', 'PURP:other', 'PURP:wedding',\n",
    "       'PURP:debt_consolidation', 'PURP:home_improvement', 'PURP:major_purchase',\n",
    "       'PURP:medical', 'PURP:moving', 'PURP:vacation', 'PURP:house', 'PURP:renewable_energy',\n",
    "       'PURP:educational')\n",
    "'''\n",
    "purpose_columns = ('PURP:credit_card', 'PURP:car', 'PURP:small_business', 'PURP:other', 'PURP:wedding',\n",
    "       'PURP:debt_consolidation', 'PURP:home_improvement', 'PURP:major_purchase',\n",
    "       'PURP:medical', 'PURP:moving', 'PURP:vacation', 'PURP:house', 'PURP:renewable_energy')\n",
    "\n",
    "purpose_encoded_dataframe = pd.DataFrame(encoded_purpose, columns= purpose_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print lcd['is_inc_v'].unique()\n",
    "# ['Verified' 'Source Verified' 'Not Verified']\n",
    "\n",
    "# backfill all NAs...in theory this might create some problems, but there aren't enough NAs to bias results. \n",
    "lcd['verification_status'].fillna(method='backfill',inplace = True)\n",
    "lcd['verification_status_b'] = (lcd['verification_status']== 'VERIFIED - income') | (lcd['verification_status'] =='VERIFIED - income source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MORTGAGE', 'RENT', 'OWN'], dtype=object)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcd.home_ownership.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert Home ownership into categorical variable and encode using One Hot Encoder\n",
    "\n",
    "# Map ownership type to categorical variable\n",
    "# lcd['home_ownership_int'] = lcd['home_ownership'].map({'RENT':0, 'OWN':1, 'MORTGAGE':2,'NONE':3,'OTHER':3})\n",
    "lcd['home_ownership_int'] = lcd['home_ownership'].map({'RENT':0, 'OWN':1, 'MORTGAGE':2,'ANY':3})\n",
    "\n",
    "lcd['home_ownership_int'].fillna(method = 'backfill', inplace= True)\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Use OHE to convert to feature columns \n",
    "encoded_ownership_status = ohe.fit_transform(lcd[['home_ownership_int']])\n",
    "\n",
    "# Now convert to dataframe and add to lcd\n",
    "# Ownship Status columns reduced to 3.  \"Other\" not present in 2015 file\n",
    "# ownership_status_columns = ('HO - Rent','HO - Own','HO - Mortgage','HO - Other')\n",
    "\n",
    "# 2015 file does not have 'Other' \n",
    "ownership_status_columns = ('HO - Rent','HO - Own','HO - Mortgage')\n",
    "ownership_encoded_dataframe = pd.DataFrame(encoded_ownership_status, columns=ownership_status_columns)\n",
    "\n",
    "lcd = pd.concat([ownership_encoded_dataframe, lcd],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print lcd['pymnt_plan'].unique()\n",
    "# ['n' 'y']\n",
    "\n",
    "# Set up calculated feature which is boolean\n",
    "lcd['pymnt_plan_bool']= (lcd['pymnt_plan']=='y').astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define 'fico_interp' as midpoint between fico_range_low and fico_range_high\n",
    "\n",
    "lcd['fico_interp']=(lcd['fico_range_low']+lcd['fico_range_high'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Current', 'In Grace Period', 'Fully Paid', 'Late (31-120 days)',\n",
       "       nan, 'Charged Off', 'Late (16-30 days)', 'Default'], dtype=object)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcd.loan_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDefaults will become our Response variable (y)\\nFOR LENDING CLUB 07-12.CSV\" file, there are additional fields \"Does not meet the credit policy.\\nSee notes from Lending Club call Jun17 15 for further info\\n LOAN STATUS CATEGORIES \\n\\'Fully Paid\\' \\'Charged Off\\' \\'Current\\' \\'Default\\' \\'Late (31-120 days)\\'\\n\\'In Grace Period\\' \\'Late (16-30 days)\\'\\n\\'Does not meet the credit policy.  Status:Current\\'\\n\\'Does not meet the credit policy.  Status:Charged Off\\'\\n\\'Does not meet the credit policy.  Status:Fully Paid\\'\\n\\'Does not meet the credit policy.  Status:Late (16-30 days)\\'\\n\\'Does not meet the credit policy.  Status:In Grace Period\\'\\n\\'Does not meet the credit policy.  Status:Late (31-120 days)\\']\\n\\nTHIS IS FOR THE 07-12 LOAN FILE ONLY\\n\\n\\nlcd[\\'loan_status_int\\']=lcd[\\'loan_status\\'].map({\\'Fully Paid\\':0,\\'Charged Off\\':1,\\'Current\\':2,\\'Default\\':3,\\n                            \\'Late (31-120 days)\\':4,\\'In Grace Period\\':5,\\'Late (16-30 days)\\':6,\\n                            \\'Does not meet the credit policy.  Status:Current\\':7,\\n                            \\'Does not meet the credit policy.  Status:Charged Off\\':8,\\n                            \\'Does not meet the credit policy.  Status:Fully Paid\\':9,\\n                            \\'Does not meet the credit policy.  Status:Late (16-30 days)\\':10,\\n                            \\'Does not meet the credit policy.  Status:In Grace Period\\':11,\\n                            \\'Does not meet the credit policy.  Status:Late (31-120 days)\\':12,\\n                            \\'Does not meet the credit policy.  Status:Default\\' :13}) \\n'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Defaults will become our Response variable (y)\n",
    "FOR LENDING CLUB 07-12.CSV\" file, there are additional fields \"Does not meet the credit policy.\n",
    "See notes from Lending Club call Jun17 15 for further info\n",
    " LOAN STATUS CATEGORIES \n",
    "'Fully Paid' 'Charged Off' 'Current' 'Default' 'Late (31-120 days)'\n",
    "'In Grace Period' 'Late (16-30 days)'\n",
    "'Does not meet the credit policy.  Status:Current'\n",
    "'Does not meet the credit policy.  Status:Charged Off'\n",
    "'Does not meet the credit policy.  Status:Fully Paid'\n",
    "'Does not meet the credit policy.  Status:Late (16-30 days)'\n",
    "'Does not meet the credit policy.  Status:In Grace Period'\n",
    "'Does not meet the credit policy.  Status:Late (31-120 days)']\n",
    "\n",
    "THIS IS FOR THE 07-12 LOAN FILE ONLY\n",
    "\n",
    "\n",
    "lcd['loan_status_int']=lcd['loan_status'].map({'Fully Paid':0,'Charged Off':1,'Current':2,'Default':3,\n",
    "                            'Late (31-120 days)':4,'In Grace Period':5,'Late (16-30 days)':6,\n",
    "                            'Does not meet the credit policy.  Status:Current':7,\n",
    "                            'Does not meet the credit policy.  Status:Charged Off':8,\n",
    "                            'Does not meet the credit policy.  Status:Fully Paid':9,\n",
    "                            'Does not meet the credit policy.  Status:Late (16-30 days)':10,\n",
    "                            'Does not meet the credit policy.  Status:In Grace Period':11,\n",
    "                            'Does not meet the credit policy.  Status:Late (31-120 days)':12,\n",
    "                            'Does not meet the credit policy.  Status:Default' :13}) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Current', 'In Grace Period', 'Fully Paid', 'Late (31-120 days)',\n",
       "       nan, 'Charged Off', 'Late (16-30 days)', 'Default'], dtype=object)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  This is for all files post 07-12 loan file\n",
    "\n",
    "lcd['loan_status_int']=lcd['loan_status'].map({'Fully Paid':0,'Charged Off':1,'Current':2,'Default':3,\n",
    "                            'Late (31-120 days)':4,'In Grace Period':5,'Late (16-30 days)':6})\n",
    "\n",
    "lcd['loan_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert loan status by using One Hot Encoder (OHE)\n",
    "\n",
    "# THere's only one na, so this shouldn't bias our results tremendously...\n",
    "lcd['loan_status_int'].fillna(method = 'backfill', inplace= True)\n",
    "\n",
    "# Use OHE to create multiple features out of loan_status_int\n",
    "encoded_loan_status = ohe.fit_transform(lcd[['loan_status_int']])\n",
    "\n",
    "# Create a dataframe to add to lcd\n",
    "'''\n",
    "# This mapping is for 07-12 file which had exceptions to the credit policy\n",
    "\n",
    "\n",
    "loan_status_columns = ('LS: Fully Paid','LS: Charged Off', 'LS: Current','LS: Default','LS: Late (31-120)',\n",
    "                      'LS: Late (Grace Period}', 'LS: Late (16-30)', 'LS: Outside Credit Policy: Current',\n",
    "                      'LS: Outside Credit Policy: Charged Off', 'LS: Outside Credit Policy: Fully Paid'\n",
    "                      'LS: Outside Credit Policy: Late (16-30)', 'LS: Outside Credit Policy: Grace Period',\n",
    "                      'LS: Outside Credit Policy: Late (31-120)', 'LS: Outside Credit Policy: (Default)')\n",
    "\n",
    "## AS OF AUG 2015, loan_status columns for 07-12 file have changed.  \n",
    "# This mapping is for 07-12 file which had exceptions to the credit policy\n",
    "\n",
    "\n",
    "loan_status_columns = ('LS: Fully Paid','LS: Charged Off', 'LS: Current','LS: Default','LS: Late (31-120)',\n",
    "                      'LS: Late (Grace Period}', 'LS: Late (16-30)', 'LS: Outside Credit Policy: Current',\n",
    "                      'LS: Outside Credit Policy: Charged Off', 'LS: Outside Credit Policy: Fully Paid')\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "loan_status_columns = ('LS: Fully Paid','LS: Charged Off', 'LS: Current','LS: Default','LS: Late (31-120)',\n",
    "                      'LS: Late (Grace Period}', 'LS: Late (16-30)')\n",
    "\n",
    "\n",
    "encoded_loan_status_dataframe = pd.DataFrame(encoded_loan_status, columns=loan_status_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Concat the categorical dataframes to lcd\n",
    "lcd = pd.concat([lcd, grade_status_encoded_dataframe], axis=1)\n",
    "lcd = pd.concat([lcd, sub_grade_status_encoded_dataframe], axis=1)\n",
    "lcd = pd.concat([lcd, encoded_loan_status_dataframe], axis=1)\n",
    "lcd = pd.concat([lcd, purpose_encoded_dataframe], axis=1)\n",
    "\n",
    "# encoded_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lcd['Total_Defaults']= lcd['LS: Default']+lcd['LS: Charged Off']+lcd['LS: Outside Credit Policy: Charged Off']\n",
    "lcd['Total_Defaults']= lcd['LS: Default']+lcd['LS: Charged Off']\n",
    "lcd['Total_Defaults'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lcd['HO - Other'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_columns = ['HO - Rent',\n",
    " 'HO - Own',\n",
    " 'HO - Mortgage',\n",
    " 'HO - Other',\n",
    " 'id',\n",
    " 'member_id',\n",
    " 'loan_amnt',\n",
    " 'funded_amnt',\n",
    " 'funded_amnt_inv',\n",
    " 'installment',\n",
    " 'emp_title',\n",
    " 'emp_length',\n",
    " 'home_ownership',\n",
    " 'annual_inc',\n",
    " 'verification_status',\n",
    " 'loan_status',\n",
    " 'pymnt_plan',\n",
    " 'url',\n",
    " 'desc',\n",
    " 'purpose',\n",
    " 'title',\n",
    " 'zip_code',\n",
    " 'addr_state',\n",
    " 'dti',\n",
    " 'delinq_2yrs',\n",
    " 'earliest_cr_line',\n",
    " 'fico_range_low',\n",
    " 'fico_range_high',\n",
    " 'inq_last_6mths',\n",
    " 'mths_since_last_delinq',\n",
    " 'mths_since_last_record',\n",
    " 'open_acc',\n",
    " 'pub_rec',\n",
    " 'revol_bal',\n",
    " 'revol_util',\n",
    " 'total_acc',\n",
    " 'initial_list_status',\n",
    " 'out_prncp',\n",
    " 'out_prncp_inv',\n",
    " 'total_pymnt',\n",
    " 'total_pymnt_inv',\n",
    " 'total_rec_prncp',\n",
    " 'total_rec_int',\n",
    " 'total_rec_late_fee',\n",
    " 'recoveries',\n",
    " 'last_fico_range_high',\n",
    " 'last_fico_range_low',\n",
    " 'collections_12_mths_ex_med',\n",
    " 'mths_since_last_major_derog',\n",
    " 'policy_code',\n",
    " 'last_pymnt_date',\n",
    " 'next_pymnt_date',\n",
    " 'last_credit_pull_date',\n",
    " 'issue_date',\n",
    " 'emp_length_numeric',\n",
    " 'clean_rate',\n",
    " 'clean_term',\n",
    " 'verification_status_b',\n",
    " 'pymnt_plan_bool',\n",
    " 'fico_interp',\n",
    " 'grade',\n",
    " 'A',\n",
    " 'B',\n",
    " 'C',\n",
    " 'D',\n",
    " 'E',\n",
    " 'F',\n",
    " 'G',\n",
    " 'A1',\n",
    " 'A2',\n",
    " 'A3',\n",
    " 'A4',\n",
    " 'A5',\n",
    " 'B1',\n",
    " 'B2',\n",
    " 'B3',\n",
    " 'B4',\n",
    " 'B5',\n",
    " 'C1',\n",
    " 'C2',\n",
    " 'C3',\n",
    " 'C4',\n",
    " 'C5',\n",
    " 'D1',\n",
    " 'D2',\n",
    " 'D3',\n",
    " 'D4',\n",
    " 'D5',\n",
    " 'E1',\n",
    " 'E2',\n",
    " 'E3',\n",
    " 'E4',\n",
    " 'E5',\n",
    " 'F1',\n",
    " 'F2',\n",
    " 'F3',\n",
    " 'F4',\n",
    " 'F5',\n",
    " 'G1',\n",
    " 'G2',\n",
    " 'G3',\n",
    " 'G4',\n",
    " 'G5',\n",
    " 'PURP:credit_card',\n",
    " 'PURP:car',\n",
    " 'PURP:small_business',\n",
    " 'PURP:other',\n",
    " 'PURP:wedding',\n",
    " 'PURP:debt_consolidation',\n",
    " 'PURP:home_improvement',\n",
    " 'PURP:major_purchase',\n",
    " 'PURP:medical',\n",
    " 'PURP:moving',\n",
    " 'PURP:vacation',\n",
    " 'PURP:house',\n",
    " 'PURP:renewable_energy',\n",
    " 'Total_Defaults',\n",
    " 'mos_to_default',\n",
    " 'mos_to_default_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# WRite file - if it exists, append to end without header.  If it doesn't already exist, write.\n",
    "write_url ='/Users/Glenn/Documents/LendingClub/LendingClub_CLEANED_v2.csv'\n",
    "\n",
    "import os\n",
    "# if file does not exist write header \n",
    "if not os.path.isfile(write_url):\n",
    "   lcd[write_columns].to_csv(write_url,header ='column_names')\n",
    "else: # else it exists so append without writing the header\n",
    "    lcd[write_columns].to_csv(write_url,mode = 'a',header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84277, 141)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cf_cohorts = lcd.groupby(lcd.issue_date)\n",
    "# cf_cohorts = lcd[lcd.issue_date=='2008-01-19T19:00:00.000000000-0500']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Glenn/Documents/LendingClub/LendingClub_13-14_CLEANED.csv\n"
     ]
    }
   ],
   "source": [
    "# write_url = url.rsplit('.')[0]+'_CLEANED.csv'\n",
    "# print write_url\n",
    "# lcd.to_csv(write_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# print lcd_temp2['issue_date'].dtype\\n# print lcd_temp2['last_pymnt_date'].dtype\\n#\\n# print lcd_temp2.issue_date.isnull().sum()\\n# print lcd_temp2.issue_date.unique()\\n# print lcd_temp2.last_pymnt_date.unique()\\n# print lcd_temp2.last_pymnt_date.isnull().sum()\\n\\n# Calculated feature measures distance between last payment date and issue date. \\n# However, default is only a subset of this. \\n# For now, we'll let default flag determine if this really is time to default\\n\\n# Drop  nulls implictly\\nlcd_temp = lcd[pd.notnull(lcd.last_pymnt_date) & pd.notnull(lcd.issue_date)]\\n\\n# Calculate datetime \\nlcd_temp['time_to_default']= (lcd_temp.last_pymnt_date - lcd_temp.issue_date)\\n\\n# Convert to days\\nlcd_temp['time_to_default'] = [j.days for j in lcd_temp.time_to_default]\\n\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# print lcd_temp2['issue_date'].dtype\n",
    "# print lcd_temp2['last_pymnt_date'].dtype\n",
    "#\n",
    "# print lcd_temp2.issue_date.isnull().sum()\n",
    "# print lcd_temp2.issue_date.unique()\n",
    "# print lcd_temp2.last_pymnt_date.unique()\n",
    "# print lcd_temp2.last_pymnt_date.isnull().sum()\n",
    "\n",
    "# Calculated feature measures distance between last payment date and issue date. \n",
    "# However, default is only a subset of this. \n",
    "# For now, we'll let default flag determine if this really is time to default\n",
    "\n",
    "# Drop  nulls implictly\n",
    "lcd_temp = lcd[pd.notnull(lcd.last_pymnt_date) & pd.notnull(lcd.issue_date)]\n",
    "\n",
    "# Calculate datetime \n",
    "lcd_temp['time_to_default']= (lcd_temp.last_pymnt_date - lcd_temp.issue_date)\n",
    "\n",
    "# Convert to days\n",
    "lcd_temp['time_to_default'] = [j.days for j in lcd_temp.time_to_default]\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
