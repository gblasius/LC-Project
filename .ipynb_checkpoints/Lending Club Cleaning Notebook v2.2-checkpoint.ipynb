{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lending Club is a \"Market Place Lender\" which allows an individual to apply for a personal loan to be filled by the market, as opposed to a bank or other specialty lender.   They have grown in success and to date have closed over $3Bn in loans.    Lending Club has made loan and performance information freely available on their website. \n",
    "\n",
    "The data is available on the Lending Club website (https://www.lendingclub.com/info/download-data.action).   I manually downloaded the CSV files and stored them locally.   I am using only one subset of the total lending club data.  \n",
    "\n",
    "My objectives in this project are threefold:\n",
    "    i) Learn how to view, clean and manipulate large datasets;\n",
    "    ii)Develop intuition for fitting estimators to the data;\n",
    "    iii) What are the best predictors of borrower default? \n",
    "    iv) What rates do borrowers pay versus their other financial options?\n",
    "    v) What are the best predictors of early borrower repayment? \n",
    "    vi) Start to develop a better way to predict creditworthiness of borrowers beyond the standard methods (eg, FICO); \n",
    "        a) For example, can we parse their loan purpose comments to develop a predictor of default?\n",
    "        b) Can I take location information (eg, via zip codes) to get a better understanding the regional economy? \n",
    "        c) Ultimately, I would like to also use complementary external data sources to allow better prediction. \n",
    "\n",
    "## AS OF THE END DATE OF THE COURSE:  \n",
    "A lot of time has been spent on cleaning, scrubbing, and understanding the organization of the data.   I had to generate some calculated features, and further projects include parsing the text fields.   \n",
    "\n",
    "\n",
    " ### This spreadsheet will be modified to do the file cleaning, with analysis and visualisation in separate notebook. \n",
    " I will take the 4 Lending Club CSV files to see if they can be 'stitched' together for processing. \n",
    " \n",
    " 22 June 15 - Added file write and append logic.   Features selected for write operation to be consistent with merge\n",
    " 31 July 15 - Attemping to merge all feature engineering and cleaning into this spradsheet.  Added 'days to default' feature.   Subsequent (separate) notebooks will do graphing and analysis.   \n",
    " \n",
    " 05 Aug - Broke up notebook into three separate notebooks:\n",
    "     i) File opening, cleaning, and appending (THIS ONE)\n",
    "     ii) Graphs\n",
    "     iii) Stats\n",
    "     \n",
    "The graph and stats notebooks work off the same file created here (currently named Lending_Club_CLEANED_V2.csv).  Some Jiggery Pokery required as LC files from 07-12 have slightly different file structure than later versions.   CUrrently no logic to handle this, as I manually comment/uncomment relevant fields.   \n",
    "\n",
    "03 Sept 15 - \n",
    "0) NEW DATA FORMAT FOR WRITING, WILL REQUIRE REWRITE OF OTHER MODULES....SEE BELOW.  \n",
    "i) Changing Logic to calculate Feature 'ROI' as actual cash flow distributions recorded by LC annualized.   \n",
    "ii) Adding Feature 'Closed' to track loans which have been paid, defaulted, liquidated.  \n",
    "iii) Renaming Engineering Feature 'Total Defaults' to 'Defaulted'\n",
    "iv) Added better logic for conversion of some dates to MMYYYY formats.   \n",
    "v) Created file of ROI grouped by rating and issue MMYYYY for Cerrid project\n",
    "\n",
    "08 Sept 15 - \n",
    "i) Changed Engineered Features 'time_to_default', 'mos_to_default', 'days_to_default', 'time_to_default_norm' to 'time_from_origination', 'mos_from_origination', 'days_from_origination', 'time_from_origination_norm' to better describe measurement\n",
    "ii) Created new filename (v.2.3) to account for the above and to avoid (future) confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load relevant libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#import dataset\n",
    "\n",
    "## THESE ARE MOST RECENT URLs FROM AUG 03 LC DOWNLOAD...\n",
    "# url = \"/Users/Glenn/Documents/LendingClub/Data/03AUG15/LC_Data_07-12_03AUG15.csv\"\n",
    "# url = \"/Users/Glenn/Documents/LendingClub/Data/03AUG15/LC_Data_12-13_03AUG15.csv\"\n",
    "# url = \"/Users/Glenn/Documents/LendingClub/Data/03AUG15/LC_Data_13-14_03AUG15.csv\"\n",
    "url = \"/Users/Glenn/Documents/LendingClub/Data/03AUG15/LC_Data_15_03AUG15.csv\"\n",
    "\n",
    "lcd_raw = pd.read_csv(url,skiprows=1,\n",
    "            parse_dates=['last_pymnt_d','issue_d','last_credit_pull_d','last_pymnt_d','next_pymnt_d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lcd_raw.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean bottom of file and create new dataframe from it\n",
    "lcd = lcd_raw[:-2].copy()\n",
    "\n",
    "# Create Datetime fields from date information....\n",
    "\n",
    "lcd['last_pymnt_date'] = [pd.to_datetime(j, format='%b-%Y', unit = \"D\") for j in lcd.last_pymnt_d]\n",
    "lcd['next_pymnt_date'] = [pd.to_datetime(j,format='%b-%Y', unit = \"D\") for j in lcd.next_pymnt_d]\n",
    "lcd['last_credit_pull_date'] = [pd.to_datetime(j, unit = \"D\",format='%b-%Y') for j in lcd.last_credit_pull_d]\n",
    "lcd['issue_date'] = [pd.to_datetime(j, format='%b-%Y', unit = \"D\") for j in lcd.issue_d]\n",
    "\n",
    "lcd['issue_MMYYYY']= lcd.issue_date.dropna().apply(lambda x: x.strftime('%m%Y'))\n",
    "lcd['last_pymnt_MMYYYY'] = lcd.last_pymnt_date.dropna().apply(lambda x: x.strftime('%m%Y'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lcd = lcd[pd.notnull(lcd.loan_amnt) & pd.notnull(lcd.last_pymnt_d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Substitute \"No Response\" for any #NA in title, desc, emp_title features\n",
    "lcd.title.fillna(value = \"No response\",inplace = True)\n",
    "lcd.desc.fillna(value=\"No response\", inplace = True)\n",
    "lcd.emp_title.fillna(value=\"No response\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace all Nan's for 'mnths_since_last_delinq',  with 999....this is a kludge for now.  If this feature is used in logistic\n",
    "# Regression, we'll want to make sure its far away from the other real delinquencies...\n",
    "lcd['mths_since_last_delinq'].fillna(value=999, inplace=True)\n",
    "lcd['mths_since_last_record'].fillna(value=999,inplace=True)\n",
    "lcd['mths_since_last_major_derog'].fillna(value=999,inplace = True)\n",
    "# lcd['mths_since_last_delinq'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Convert Field Employment Length into a numeric...\n",
    "#lcd.emp_length.unique()\n",
    "#array(['10+ years', , '1 year', '3 years', '8 years', '9 years',\n",
    "#        '4 years', '5 years', '6 years', '2 years', '7 years', 'n/a'], dtype=object)\n",
    "\n",
    "lcd['emp_length_numeric'] = lcd['emp_length'].map({'< 1 year':0, '1 year':1, '2 years':2, '3 years':3, \n",
    "                                                  '4 years':4,'5 years':5,'6 years':6,'7 years':7,\n",
    "                                                  '8 years':8,'9 years':9,'10+ years':10})\n",
    "\n",
    "# Now graph\n",
    "# lcd['emp_length_numeric'].hist()\n",
    "# plt.title('Employment Length counts')\n",
    "# plt.xlabel('Employment Length (yrs)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Employment length reasonably evenly distributed out to 5 years.    How is this distributed versus FICO score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Strip chars, convert int_rate series to float\n",
    "lcd.int_rate.fillna(method='backfill',inplace = True)\n",
    "lcd['clean_rate'] = [float(t.strip(' %'))/100 for t in lcd.int_rate]\n",
    "\n",
    "# Now graph!\n",
    "# lcd['clean_rate'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean term by splitting on spaces and converting numbers into float\n",
    "lcd.term.fillna(method='backfill',inplace = True)\n",
    "lcd['clean_term'] = [float (s.split(' ')[1]) for s in lcd.term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate time from origination to latest payment, assumes we will flag the correct values through state variable\n",
    "\n",
    "lcd = lcd[pd.notnull(lcd.last_pymnt_date) & pd.notnull(lcd.issue_date)]\n",
    "lcd['time_from_origination'] = lcd['last_pymnt_date'] - lcd['issue_date']\n",
    "lcd['days_from_origination'] = [j.days for j in lcd.time_from_origination]\n",
    "lcd['mos_from_origination'] = [round(float(j/30),0) for j in lcd.days_from_origination]\n",
    "\n",
    "# Create normalized mos to default. \n",
    "lcd['time_from_origination_norm'] = lcd['mos_from_origination']/lcd['clean_term']\n",
    "lcd['time_from_origination_norm'] = [min(i,1) for i in lcd.time_from_origination_norm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Sub Grade map \n",
    "# print lcd['sub_grade'].unique()\n",
    "#['B2' 'C4' 'C5' 'C1' 'B5' 'A4' 'E1' 'F2' 'C3' 'B1' 'D1' 'A1' 'B3' 'B4' 'C2'\n",
    "# 'D2' 'A3' 'A5' 'D5' 'A2' 'E4' 'D3' 'D4' 'F3' 'E3' 'F4' 'F1' 'E5' 'G4' 'E2'\n",
    "# 'G3' 'G2' 'G1' 'F5' 'G5']\n",
    "\n",
    "lcd['sub_grade_int']=lcd['sub_grade'].map({'A1':0,'A2':1,'A3':2,'A4':3,'A5':4,\n",
    "                                           'B1':5,'B2':6,'B3':7,'B4':8,'B5':9,\n",
    "                                           'C1':10,'C2':11,'C3':12,'C4':13,'C5':14,\n",
    "                                           'D1':15,'D2':16,'D3':17,'D4':18,'D5':19,\n",
    "                                           'E1':20,'E2':21,'E3':22,'E4':23,'E5':24,\n",
    "                                           'F1':25,'F2':26,'F3':27,'F4':28,'F5':29,\n",
    "                                           'G1':30,'G2':31,'G3':32,'G4':33,'G5':34})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Categorical Variable from LC grades\n",
    "lcd['grade_int']=lcd['grade'].map({'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  THIS IS A KLUDGE TO GET RID OF NAs BY USING BACKFILL....\n",
    "\n",
    "lcd['grade_int'].fillna(method = 'backfill',inplace = True)\n",
    "lcd['sub_grade_int'].fillna(method='backfill',inplace=True)\n",
    "lcd['purpose'].fillna(method = 'backfill',inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use One Hot Encoder to turn Grade, Grade_Int into categorical variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "encoded_grade_status = ohe.fit_transform(lcd[['grade_int']])\n",
    "\n",
    "# Convert to dataframe and add to lcd\n",
    "grade_status_columns = ('A','B','C','D','E','F','G')\n",
    "grade_status_encoded_dataframe = pd.DataFrame(encoded_grade_status, columns=grade_status_columns)\n",
    "\n",
    "# Add to lcd dataframe at end so we avoid problems with re-running cells\n",
    "\n",
    "# Now do the same for subgrade.   \n",
    "encoded_sub_grade_status = ohe.fit_transform(lcd[['sub_grade_int']])\n",
    "sub_grade_status_columns = ('A1','A2','A3','A4','A5',\n",
    "                            'B1','B2','B3','B4','B5',\n",
    "                            'C1','C2','C3','C4','C5',\n",
    "                            'D1','D2','D3','D4','D5',\n",
    "                            'E1','E2','E3','E4','E5',\n",
    "                            'F1','F2','F3','F4','F5',\n",
    "                            'G1','G2','G3','G4','G5')\n",
    "sub_grade_status_encoded_dataframe = pd.DataFrame(encoded_sub_grade_status, columns=sub_grade_status_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use One Hot Encoder to turn Grade, Grade_Int into categorical variables\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "lcd.purpose.unique()\n",
    "\n",
    "'''\n",
    "# This is for 07-12 File.  \"Education\" Purpose removed in subsequent files.\n",
    "lcd['purpose_int']= lcd['purpose'].map({'credit_card':0, 'car':2, 'small_business':3, 'other':4, \n",
    "                                        'wedding':5,'debt_consolidation':6, 'home_improvement':7, \n",
    "                                        'major_purchase':8, 'medical':9, 'moving':10, 'vacation':11, \n",
    "                                        'house':12, 'renewable_energy':13,'educational':14})\n",
    "'''\n",
    "\n",
    "lcd['purpose_int']= lcd['purpose'].map({'credit_card':0, 'car':2, 'small_business':3, 'other':4, \n",
    "                                        'wedding':5,'debt_consolidation':6, 'home_improvement':7, \n",
    "                                        'major_purchase':8, 'medical':9, 'moving':10, 'vacation':11, \n",
    "                                        'house':12, 'renewable_energy':13})\n",
    "\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "encoded_purpose = ohe.fit_transform(lcd[['purpose_int']])\n",
    "\n",
    "'''\n",
    "# See above comments for 07-12 file \n",
    "purpose_columns = ('PURP:credit_card', 'PURP:car', 'PURP:small_business', 'PURP:other', 'PURP:wedding',\n",
    "       'PURP:debt_consolidation', 'PURP:home_improvement', 'PURP:major_purchase',\n",
    "       'PURP:medical', 'PURP:moving', 'PURP:vacation', 'PURP:house', 'PURP:renewable_energy',\n",
    "       'PURP:educational')\n",
    "'''\n",
    "purpose_columns = ('PURP:credit_card', 'PURP:car', 'PURP:small_business', 'PURP:other', 'PURP:wedding',\n",
    "       'PURP:debt_consolidation', 'PURP:home_improvement', 'PURP:major_purchase',\n",
    "       'PURP:medical', 'PURP:moving', 'PURP:vacation', 'PURP:house', 'PURP:renewable_energy')\n",
    "\n",
    "purpose_encoded_dataframe = pd.DataFrame(encoded_purpose, columns= purpose_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print lcd['is_inc_v'].unique()\n",
    "# ['Verified' 'Source Verified' 'Not Verified']\n",
    "\n",
    "# backfill all NAs...in theory this might create some problems, but there aren't enough NAs to bias results. \n",
    "lcd['verification_status'].fillna(method='backfill',inplace = True)\n",
    "lcd['verification_status_b'] = (lcd['verification_status']== 'VERIFIED - income') | (lcd['verification_status'] =='VERIFIED - income source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MORTGAGE', 'RENT', 'OWN'], dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcd.home_ownership.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert Home ownership into categorical variable and encode using One Hot Encoder\n",
    "\n",
    "# Map ownership type to categorical variable\n",
    "# lcd['home_ownership_int'] = lcd['home_ownership'].map({'RENT':0, 'OWN':1, 'MORTGAGE':2,'NONE':3,'OTHER':3})\n",
    "# lcd['home_ownership_int'] = lcd['home_ownership'].map({'RENT':0, 'OWN':1, 'MORTGAGE':2,'ANY':3})\n",
    "lcd['home_ownership_int'] = lcd['home_ownership'].map({'RENT':0, 'OWN':1, 'MORTGAGE':2})\n",
    "lcd['home_ownership_int'].fillna(method = 'backfill', inplace= True)\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Use OHE to convert to feature columns \n",
    "encoded_ownership_status = ohe.fit_transform(lcd[['home_ownership_int']])\n",
    "\n",
    "# Now convert to dataframe and add to lcd\n",
    "# Ownship Status columns reduced to 3.  \"Other\" not present in 2015 file\n",
    "# ownership_status_columns = ('HO - Rent','HO - Own','HO - Mortgage','HO - Other')\n",
    "\n",
    "# 2015 file does not have 'Other' \n",
    "ownership_status_columns = ('HO - Rent','HO - Own','HO - Mortgage')\n",
    "ownership_encoded_dataframe = pd.DataFrame(encoded_ownership_status, columns=ownership_status_columns)\n",
    "\n",
    "lcd = pd.concat([ownership_encoded_dataframe, lcd],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print lcd['pymnt_plan'].unique()\n",
    "# ['n' 'y']\n",
    "\n",
    "# Set up calculated feature which is boolean\n",
    "lcd['pymnt_plan_bool']= (lcd['pymnt_plan']=='y').astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define 'fico_interp' as midpoint between fico_range_low and fico_range_high\n",
    "\n",
    "lcd['fico_interp']=(lcd['fico_range_low']+lcd['fico_range_high'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Defaults will become our Response variable (y)\n",
    "FOR LENDING CLUB 07-12.CSV\" file, there are additional fields \"Does not meet the credit policy.\n",
    "See notes from Lending Club call Jun17 15 for further info\n",
    " LOAN STATUS CATEGORIES \n",
    "'Fully Paid' 'Charged Off' 'Current' 'Default' 'Late (31-120 days)'\n",
    "'In Grace Period' 'Late (16-30 days)'\n",
    "'Does not meet the credit policy.  Status:Current'\n",
    "'Does not meet the credit policy.  Status:Charged Off'\n",
    "'Does not meet the credit policy.  Status:Fully Paid'\n",
    "'Does not meet the credit policy.  Status:Late (16-30 days)'\n",
    "'Does not meet the credit policy.  Status:In Grace Period'\n",
    "'Does not meet the credit policy.  Status:Late (31-120 days)']\n",
    "\n",
    "THIS IS FOR THE 07-12 LOAN FILE ONLY\n",
    "\n",
    "'''\n",
    "lcd['loan_status_int']=lcd['loan_status'].map({'Fully Paid':0,'Charged Off':1,'Current':2,'Default':3,\n",
    "                            'Late (31-120 days)':4,'In Grace Period':5,'Late (16-30 days)':6,\n",
    "                            'Does not meet the credit policy.  Status:Current':7,\n",
    "                            'Does not meet the credit policy.  Status:Charged Off':8,\n",
    "                            'Does not meet the credit policy.  Status:Fully Paid':9,\n",
    "                            'Does not meet the credit policy.  Status:Late (16-30 days)':10,\n",
    "                            'Does not meet the credit policy.  Status:In Grace Period':11,\n",
    "                            'Does not meet the credit policy.  Status:Late (31-120 days)':12,\n",
    "                            'Does not meet the credit policy.  Status:Default' :13}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Current', 'In Grace Period', 'Fully Paid', 'Late (31-120 days)',\n",
       "       nan, 'Charged Off', 'Late (16-30 days)', 'Default'], dtype=object)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  This is for all files post 07-12 loan file\n",
    "\n",
    "lcd['loan_status_int']=lcd['loan_status'].map({'Fully Paid':0,'Charged Off':1,'Current':2,'Default':3,\n",
    "                            'Late (31-120 days)':4,'In Grace Period':5,'Late (16-30 days)':6})\n",
    "\n",
    "lcd['loan_status'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert loan status by using One Hot Encoder (OHE)\n",
    "\n",
    "# THere's only one na, so this shouldn't bias our results tremendously...\n",
    "lcd['loan_status_int'].fillna(method = 'backfill', inplace= True)\n",
    "\n",
    "# Use OHE to create multiple features out of loan_status_int\n",
    "encoded_loan_status = ohe.fit_transform(lcd[['loan_status_int']])\n",
    "\n",
    "# Create a dataframe to add to lcd\n",
    "'''\n",
    "# This mapping is for 07-12 file which had exceptions to the credit policy\n",
    "\n",
    "\n",
    "loan_status_columns = ('LS: Fully Paid','LS: Charged Off', 'LS: Current','LS: Default','LS: Late (31-120)',\n",
    "                      'LS: Late (Grace Period}', 'LS: Late (16-30)', 'LS: Outside Credit Policy: Current',\n",
    "                      'LS: Outside Credit Policy: Charged Off', 'LS: Outside Credit Policy: Fully Paid'\n",
    "                      'LS: Outside Credit Policy: Late (16-30)', 'LS: Outside Credit Policy: Grace Period',\n",
    "                      'LS: Outside Credit Policy: Late (31-120)', 'LS: Outside Credit Policy: (Default)')\n",
    "\n",
    "## AS OF AUG 2015, loan_status columns for 07-12 file have changed.  \n",
    "# This mapping is for 07-12 file which had exceptions to the credit policy\n",
    "\n",
    "\n",
    "loan_status_columns = ('LS: Fully Paid','LS: Charged Off', 'LS: Current','LS: Default','LS: Late (31-120)',\n",
    "                      'LS: Late (Grace Period}', 'LS: Late (16-30)', 'LS: Outside Credit Policy: Current',\n",
    "                      'LS: Outside Credit Policy: Charged Off', 'LS: Outside Credit Policy: Fully Paid')\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "loan_status_columns = ('LS: Fully Paid','LS: Charged Off', 'LS: Current','LS: Default','LS: Late (31-120)',\n",
    "                      'LS: Late (Grace Period}', 'LS: Late (16-30)')\n",
    "\n",
    "\n",
    "encoded_loan_status_dataframe = pd.DataFrame(encoded_loan_status, columns=loan_status_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Concat the categorical dataframes to lcd\n",
    "lcd = pd.concat([lcd, grade_status_encoded_dataframe], axis=1)\n",
    "lcd = pd.concat([lcd, sub_grade_status_encoded_dataframe], axis=1)\n",
    "lcd = pd.concat([lcd, encoded_loan_status_dataframe], axis=1)\n",
    "lcd = pd.concat([lcd, purpose_encoded_dataframe], axis=1)\n",
    "\n",
    "# encoded_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lcd['Total_Defaults']= lcd['LS: Default']+lcd['LS: Charged Off']+lcd['LS: Outside Credit Policy: Charged Off']\n",
    "lcd['Defaulted']= lcd['LS: Default']+lcd['LS: Charged Off']\n",
    "\n",
    "# Closed files are those which have matured or been written off...\n",
    "# THis is for 07-12 files which contain loans which are classified as \"Outside Credit Policy\"\n",
    "# lcd['Closed'] = lcd['LS: Default']+lcd['LS: Charged Off']+lcd['LS: Fully Paid']+lcd['LS: Outside Credit Policy: Charged Off']+lcd['LS: Outside Credit Policy: Fully Paid']\n",
    "# THis is for subsequent files and years...\n",
    "lcd['Closed'] = lcd['LS: Default']+lcd['LS: Charged Off']+lcd['LS: Fully Paid']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate ROI defined as total payments received divided by the total amount funded, annualized  \n",
    "lcd['ROI'] = (lcd['total_pymnt']/lcd['funded_amnt'])**(12/lcd['mos_from_origination'])-1\n",
    "# lcd['ROI'] = lcd['total_pymnt']/lcd['funded_amnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': [<matplotlib.lines.Line2D at 0x114b73690>,\n",
       "  <matplotlib.lines.Line2D at 0x10922d950>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x109237650>,\n",
       "  <matplotlib.lines.Line2D at 0x109237c90>,\n",
       "  <matplotlib.lines.Line2D at 0x109246c50>,\n",
       "  <matplotlib.lines.Line2D at 0x10f5172d0>],\n",
       " 'fliers': [],\n",
       " 'means': [],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x10922d310>,\n",
       "  <matplotlib.lines.Line2D at 0x10f517910>],\n",
       " 'whiskers': [<matplotlib.lines.Line2D at 0x114b73910>,\n",
       "  <matplotlib.lines.Line2D at 0x114b73fd0>,\n",
       "  <matplotlib.lines.Line2D at 0x10922df90>,\n",
       "  <matplotlib.lines.Line2D at 0x109246610>]}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAh4AAAFxCAYAAAA8iaFYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAE59JREFUeJzt3V+o5Od93/HP7CqrRtauMSUtFlvOFuJ8EyTkCy1IlopT\n",
       "UURaY8HGxgVTCChSSrARuZJjUuKbFFIiFIJTlAZFdih1KCzYbk2RXNcxmKyxIDhEEcVfWTLnpDK+\n",
       "MKbdVTeVbK2mF2d2NVq0Z1Y+M8+c3Xm9QHBmnnl+5xHsb/a9z/z5TabTaQAARji07gUAAJtDeAAA\n",
       "wwgPAGAY4QEADCM8AIBhhAcAMMwNew1W1aEkjye5PcmrSR7q7hfnxj+c5DeTTJN8rrs/Pbv/W0nO\n",
       "zh723e5+cAVrBwCuMXuGR5JTSY50991VdWeSx2b3paoOJ/ndJHckOZ/kf1bVf0ryd0nS3feubNUA\n",
       "wDVp0Ust9yR5Okm6+5kkJy8OdPeFJD/f3S8n+Zkkh5P8KMl7k9xUVV+uqq/OggUAYGF4HEtybu72\n",
       "hdnLL0mS7n69qj6U5K+SfC27ux3nkzza3b+U5NeTfG5+DgCwuRa91HIuydG524e6+/X5B3T356vq\n",
       "C0n+NMmvJPmzJC/Mxr5TVT9M8u4k39vj9zyX5Na3t3QA4ICaXGlgUXicSXJ/ktNVdVeSZy8OVNWx\n",
       "JF9Kcl93/6iqzie5kOSB7L4Z9eNVdUt2d02+v+D33Lbwf4Hr0TR7/OEErhvOdS6Z7HWRuKqa5I1P\n",
       "tSS7UXFHkpu7+4mq+rUkDyb5cZK/TvJwdt/r8dkkW7M5n+jub65m+VzjPBnBZnCuc8me4QEr5skI\n",
       "NoNznUu86RMAGEZ4AADDCA8AYBjhAQAMIzwAgGEWfY8HABtmMsmjST6yrONtbSU7O9lewqFOT6d5\n",
       "ZAnHYY3seABwuY8kOb7uRVzmeJYYQ6yPHQ8A3spL02lOLOlY02R/x5pMlrJjwgFgxwMAGEZ4AADD\n",
       "CA8AYBjhAQAMIzwAgGGEBwAwjPAAAIYRHgDAMMIDABhGeAAAwwgPAGAY4QEADCM8AIBhhAcAMIzw\n",
       "AACGER4AwDDCAwAYRngAAMMIDwBgGOEBAAwjPACAYYQHADCM8AAAhhEeAMAwwgMAGEZ4AADDCA8A\n",
       "YBjhAQAMIzwAgGGEBwAwjPAAAIYRHgDAMDfsNVhVh5I8nuT2JK8meai7X5wb/3CS30wyTfK57v70\n",
       "ojkAwOZatONxKsmR7r47ySeTPHZxoKoOJ/ndJP8syfuSfKyq/v5szo1vNQcA2GyLwuOeJE8nSXc/\n",
       "k+TkxYHuvpDk57v75SQ/k+Rwkh/N5jz1VnMAgM22KDyOJTk3d/vC7KWUJEl3v15VH0ryV0m+luT8\n",
       "ojkAwOba8z0e2Q2Io3O3D3X36/MP6O7PV9UXkvxpkl+5mjlv4bkkt17VirneTNe9AODNtrYu/bjM\n",
       "83Nfx1rRmlidyZUGFoXHmST3JzldVXclefbiQFUdS/KlJPd194+q6nySC3vN2cNtV/EYrj/T7PGH\n",
       "E1iPnZ1sz348saRD7vtcX8GaWJPJdHrleKyqSd74hEqSPJDkjiQ3d/cTVfVrSR5M8uMkf53k4dnj\n",
       "3jSnu59fwdq59gkPOIAmk92/5KfTgxMeK1gTa7JneMCKCQ84gIQHq+RNnwDAMMIDABhGeAAAwwgP\n",
       "AGAY4QEADCM8AIBhhAcAMIzwAACGER4AwDDCAwAYRngAAMMIDwBgGOEBAAwjPACAYYQHADCM8AAA\n",
       "hhEeAMAwwgMAGEZ4AADDCA8AYBjhAQAMIzwAgGGEBwAwjPAAAIYRHgDAMMIDABhGeAAAwwgPAGAY\n",
       "4QEADCM8AIBhhAcAMIzwAACGER4AwDDCAwAYRngAAMMIDwBgGOEBAAwjPACAYYQHADCM8AAAhrlh\n",
       "r8GqOpTk8SS3J3k1yUPd/eLc+EeT/EaS15L8TZKPdfe0qr6V5OzsYd/t7gdXsXgA4NqyZ3gkOZXk\n",
       "SHffXVV3Jnlsdl+q6qeT/E6S27r7lar6syQfrKqvJEl337vCdQMA16BFL7Xck+TpJOnuZ5KcnBt7\n",
       "Jcn7uvuV2e0bkvy/JO9NclNVfbmqvjoLFgCAheFxLMm5udsXZi+/pLun3f2DJKmqh5O8o7v/R5Lz\n",
       "SR7t7l9K8utJPndxDgCw2Ra91HIuydG524e6+/WLN2ZB8XtJfjbJh2d3P5/khSTp7u9U1Q+TvDvJ\n",
       "9/b4Pc8lufXtLZ3rxHTdCwDebGvr0o/LPD/3dawVrYnVmVxpYFF4nElyf5LTVXVXkmcvG//j7L7k\n",
       "8svdffEPwwPZfTPqx6vqluzumnx/we+5bcE416dp9vjDCazHzk62Zz+eWNIh932ur2BNrMlkOr1y\n",
       "PFbVJG98qiXZjYo7ktyc5C9n/319bsofJPlvST6b5GKffqK7v7ncZXOdEB5wAE0mu3/JT6cHJzxW\n",
       "sCbWZM/wgBUTHnAACQ9WyZs+AYBhhAcAMIzwAACGER4AwDDCAwAYRngAAMMIDwBgGOEBAAwjPACA\n",
       "YYQHADCM8AAAhhEeAMAwwgMAGEZ4AADDCA8AYBjhAQAMIzwAgGGEBwAwjPAAAIYRHgDAMMIDABhG\n",
       "eAAAwwgPAGAY4QEADCM8AIBhhAcAMIzwAACGER4AwDDCAwAYRngAAMMIDwBgGOEBAAwjPACAYYQH\n",
       "ADCM8AAAhrlh3QsA4GD5dB5+16l88R2ZvLS9lANubSU7O/s61t/m+PEv5tT55A+XsiTWR3hw1SaT\n",
       "PJrkI8s63u5zUbaXcKjT02keWcJxAFixyXQ6XfcauEZMJtlOcjzJS8s43tZWtnZ2srPPwxxP8tJ0\n",
       "mhNLWBKQS+d6lnheTZNM9nOAFayJNbHjwdu1zL/kp8n+jnXxyQiAa4M3lwIAw+y541FVh5I8nuT2\n",
       "JK8meai7X5wb/2iS30jyWpK/SfKx7G6nXXEOALC5Fu14nEpypLvvTvLJJI9dHKiqn07yO0n+aXf/\n",
       "kyTvTPLB2Zwb32oOALDZFoXHPUmeTpLufibJybmxV5K8r7tfmd2+YXbfPUmeusIcAGCDLXpz6bEk\n",
       "5+ZuX6iqQ939endPk/wgSarq4STv6O6vVNW/vNKcPX7Pc0lu/QnWz0BbW5d+XOZHofZ1rBWtCTaa\n",
       "c50luOKnmBaFx7kkR+duvykgZu8B+b0kP5vkw1cz5wpuWzDOATD3nRsnlnTIfX/EbgVrgo3nXGeV\n",
       "Fr3UcibJB5Kkqu5K8uxl43+c5MYkvzz3ksuiOQDAhtrzC8Sqav4TKknyQJI7ktyc5C9n/319bsof\n",
       "JPmvl8/p7ueXu2zWwZcKwWZwrrNKvrmUq+bJCDaDc51V8gViAMAwwgMAGEZ4AADDCA8AYBjhAQAM\n",
       "IzwAgGGEBwAwjPAAAIYRHgDAMMIDABhGeAAAwwgPAGAY4QEADCM8AIBhhAcAMIzwAACGER4AwDDC\n",
       "AwAYRngAAMMIDwBgGOEBAAwjPACAYYQHADCM8AAAhhEeAMAwwgMAGEZ4AADDCA8AYBjhAQAMIzwA\n",
       "gGGEBwAwjPAAAIYRHgDAMMIDABhGeAAAwwgPAGAY4QEADCM8AIBhhAcAMIzwAACGuWGvwao6lOTx\n",
       "JLcneTXJQ9394mWPuSnJV5L8anf37L5vJTk7e8h3u/vBZS8cALj27BkeSU4lOdLdd1fVnUkem92X\n",
       "JKmqk0n+Q5Jbkkxn9/29JOnue1eyYgDgmrXopZZ7kjydJN39TJKTl40fyW6I9Nx9701yU1V9uaq+\n",
       "OgsWAICFOx7Hkpybu32hqg519+tJ0t3fSJKqmp9zPsmj3f1kVb0nyVNV9XMX51zBc0lufdurZ6it\n",
       "rUs/Tpd42H0da0Vrgo3mXGcJJlcaWBQe55Icnbt9aEFAJMnzSV5Iku7+TlX9MMm7k3xvjzm3LTgm\n",
       "B8DOTrZnP55Y0iGn2eMP59VYwZpg4znXWaVFL7WcSfKBJKmqu5I8exXHfCC77wVJVd2S3V2T7+9j\n",
       "jQDAdWLRjscXktxXVWdmtx+oqo8mubm7n7jCnCeTfLaqvn5xzlXskgBwcGwlyWRyaZdhfwfbetOO\n",
       "xU/qeJKXlrAc1mwynXq5jKtz8UloOj04268rWBNsvMnk0vsodpZwuOOHD+fwhQtLOdbp6TSPLOE4\n",
       "rNGiHQ8ANsx0ur9/EMybTLJ9/Hi2trf944BdvrkUABhGeAAAw3iphav26Tz8rlP54jsyeWl7KQfc\n",
       "fcfZvo71tzl+/Is5dT75w6UsCYDVsuMBAAzjUy1cNZ9qAX5C+z7XuX7Y8QAAhhEeAMAwwgMAGEZ4\n",
       "AADDCA8AYBjhAcDKTCbZPnFi3avgIBEeAMAwwgMAGEZ4AADDCA8AYBjhAQAM4+q0AKzM7DpKLgrG\n",
       "JXY8AIBhhAcAMIzwAACGER4AwDDCAwAYRngAsDKu1cLlhAcAMIzwAACGER4AwDDCAwAYRngAAMO4\n",
       "VgsAK+NaLVzOjgcAMIzwAACGER4AwDDCAwAYRngAAMMIDwBWxrVauJzwAACGER4AwDDCAwAYZs9v\n",
       "Lq2qQ0keT3J7kleTPNTdL172mJuSfCXJr3Z3X80cAGAzLdrxOJXkSHffneSTSR6bH6yqk0m+nuQf\n",
       "542vxN1zDgCwuRaFxz1Jnk6S7n4mycnLxo9kNzT6bcwBYENMpzmxvb3uVXCQLAqPY0nOzd2+MHsp\n",
       "JUnS3d/o7pfezhwAYHMtujrtuSRH524f6u7XVzDnuSS3LngMB8SJE0u90uS+jnX4cHL8+P6PA6yc\n",
       "c3SzTK40sCg8ziS5P8npqrorybNX8ct+kjm3XcVjWL9pkuzsZGcJxzp++HAOX7iw/2Pt7OR0kkeW\n",
       "sCZgNabZ4y8iNsui8PhCkvuq6szs9gNV9dEkN3f3E1c7Zwnr5ACYTpf3xDGZZPv48Wxtb+fEso4J\n",
       "wME3mU7tfjHeZJLtra1sbW/7VxBsADseXOJNnwCsjGu1cDnhAQAMIzwAgGEWvbkUVmI6zYn4eB3A\n",
       "xrHjAQAMIzwAgGF8nJZ18hE72AzOdS6x4wEADCM8AIBhhAdr4UuFADaT8AAAhhEeAMAwwgOAlfGy\n",
       "KpcTHgDAMMIDABjGtVpYC9dqAdhMdjwAgGGEBwAwjGu1sE6u3wCbwbnOJXY8AIBhhAcAMIzwYC18\n",
       "qRDAZhIeAMAwwgMAGEZ4ALAyXlblcsIDABhGeAAAw7hWC2vhWi0Am8mOBwAwjPAAAIZxrRbWyfUb\n",
       "YDM417nEjgcAMIzwAACGER6shS8VAthMwgMAGEZ4AADDCA8AVsbLqlxOeAAAwwgPAGAY12phLVyr\n",
       "BWAz7RkeVXUoyeNJbk/yapKHuvvFufH7k/x2kteSfKa7/2R2/7eSnJ097Lvd/eAK1g4AXGMW7Xic\n",
       "SnKku++uqjuTPDa7L1X1U0l+P8nJJH+X5ExV/ZckLydJd9+7slVzYE0mk0eTfORqHru1tZWdnZ3t\n",
       "BQ87PZ1OH9n3wgA4EBaFxz1Jnk6S7n6mqk7Ojf1Ckhe6+2ySVNVfJPnFJP8ryU1V9eXZ8X+ru59Z\n",
       "+soBOPC8rMrlFoXHsSTn5m5fqKpD3f36bOzs3NjLSd6Z5NtJHu3uJ6vqPUmeqqqfm83hOjfbnbja\n",
       "HYppkhOrWw0AB82i8DiX5Ojc7UNzAXH2srGjSf53kueTvJAk3f2dqvphkncn+d4ev+e5JLe+jXVz\n",
       "/fAvIdgMzvXNcsWrES8KjzNJ7k9yuqruSvLs3Ni3k7ynqt6V5HyS9yd5NMkD2X0z6ser6pbs7ox8\n",
       "f8HvuW3BONcnl8qGzeBc55LJdHrlCK2qSd74VEuyGxV3JLm5u5+oqg8m+VR2vw/kye7+o6q6Icln\n",
       "k2zN5nyiu7+5qv8BrmmejGAzONe5ZM/wgBXzZATXqLf5CbatnZ2dnQUP8wm2DeGbSwGAYex4sE52\n",
       "PGAzONe5xI4HADCM8AAAhhEeAMAwwgMAGEZ4AADDCA8AYBjhAQAMIzwAgGGEBwAwjPAAAIYRHgDA\n",
       "MMIDABhGeAAAwwgPAGAY4QEADCM8AIBhhAcAMIzwAACGER4AwDDCAwAYRngAAMMIDwBgGOEBAAwj\n",
       "PACAYYQHADCM8AAAhhEeAMAwwgMAGEZ4AADDCA8AYBjhAQAMIzwAgGGEBwAwjPAAAIYRHgDAMMID\n",
       "ABhGeAAAwwgPAGCYG/YarKpDSR5PcnuSV5M81N0vzo3fn+S3k7yW5DPd/SeL5gAAm2vRjsepJEe6\n",
       "++4kn0zy2MWBqvqpJL+f5L4kv5jkX1fVP5jNufGt5gAAm21ReNyT5Okk6e5nkpycG/uFJC9099nu\n",
       "/nGSv0jy/tmcp64wBwDYYIvC41iSc3O3L8xeSrk4dnZu7OUk71wwBwDYYIuC4FySo/OP7+7XZz+f\n",
       "vWzsaJL/s2AOzJusewHAEM51LlkUHmeSfCBJququJM/OjX07yXuq6l1VdSS7L7N8Y8EcAGCDTabT\n",
       "6RUHq2qSNz6hkiQPJLkjyc3d/URVfTDJp7IbME929x+91Zzufn5V/wMAwLVjz/AAAFgmb/oEAIYR\n",
       "HgDAMMIDABhmz69Mh1WpqjuT/LvuvnfdawGWb/bt1p9JspXkxiT/tru/tN5VcRDY8WC4qvpEkiey\n",
       "+2QEXJ/+VZIfdPf7k/zzJP9+zevhgBAerMMLST4UXyoE17PT2f26hWT375rX1rgWDhDhwXDd/fl4\n",
       "EoLrWnef7+7/W1VHsxsh/2bda+JgEB4ArERV/aMkf57kP3b3f173ejgYvLkUgKWrqn+Y5L8n+Vh3\n",
       "f23d6+HgEB6sk6/NhevXb2X3iuWfqqqL7/X4F939yhrXxAHgK9MBgGG8xwMAGEZ4AADDCA8AYBjh\n",
       "AQAMIzwAgGGEBwAwjPAAAIYRHgDAMP8fC1GuesjpVREAAAAASUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108e89790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot test.   Only select closed files.  \n",
    "\n",
    "from pylab import *\n",
    "\n",
    "# fig, ax = plt.plot(figsize=(12,9)) \n",
    "data = [lcd[(lcd['Closed']==1) & (lcd['clean_term']==36)].ROI,lcd[(lcd['Closed']==1) & (lcd['clean_term']==60)].ROI]\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "\n",
    "# plt.ylim([-0.30, 0.20])\n",
    "\n",
    "boxplot(data, whis = [5,95],showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Necessary for the 2015 file which does not have an HO - Other categorical \n",
    "lcd['HO - Other'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_columns = ['HO - Rent',\n",
    " 'HO - Own',\n",
    " 'HO - Mortgage',\n",
    " 'HO - Other',\n",
    " 'id',\n",
    " 'member_id',\n",
    " 'loan_amnt',\n",
    " 'funded_amnt',\n",
    " 'funded_amnt_inv',\n",
    " 'installment',\n",
    " 'emp_title',\n",
    " 'emp_length',\n",
    " 'home_ownership',\n",
    " 'annual_inc',\n",
    " 'verification_status',\n",
    " 'loan_status',\n",
    " 'pymnt_plan',\n",
    " 'url',\n",
    " 'desc',\n",
    " 'purpose',\n",
    " 'title',\n",
    " 'zip_code',\n",
    " 'addr_state',\n",
    " 'dti',\n",
    " 'delinq_2yrs',\n",
    " 'earliest_cr_line',\n",
    " 'fico_range_low',\n",
    " 'fico_range_high',\n",
    " 'inq_last_6mths',\n",
    " 'mths_since_last_delinq',\n",
    " 'mths_since_last_record',\n",
    " 'open_acc',\n",
    " 'pub_rec',\n",
    " 'revol_bal',\n",
    " 'revol_util',\n",
    " 'total_acc',\n",
    " 'initial_list_status',\n",
    " 'out_prncp',\n",
    " 'out_prncp_inv',\n",
    " 'total_pymnt',\n",
    " 'total_pymnt_inv',\n",
    " 'total_rec_prncp',\n",
    " 'total_rec_int',\n",
    " 'total_rec_late_fee',\n",
    " 'recoveries',\n",
    " 'last_fico_range_high',\n",
    " 'last_fico_range_low',\n",
    " 'collections_12_mths_ex_med',\n",
    " 'mths_since_last_major_derog',\n",
    " 'policy_code',\n",
    " 'last_pymnt_date',\n",
    " 'next_pymnt_date',\n",
    " 'last_credit_pull_date',\n",
    " 'issue_date',\n",
    " 'emp_length_numeric',\n",
    " 'clean_rate',\n",
    " 'clean_term',\n",
    " 'verification_status_b',\n",
    " 'pymnt_plan_bool',\n",
    " 'fico_interp',\n",
    " 'grade',\n",
    " 'sub_grade',\n",
    " 'A',\n",
    " 'B',\n",
    " 'C',\n",
    " 'D',\n",
    " 'E',\n",
    " 'F',\n",
    " 'G',\n",
    " 'A1',\n",
    " 'A2',\n",
    " 'A3',\n",
    " 'A4',\n",
    " 'A5',\n",
    " 'B1',\n",
    " 'B2',\n",
    " 'B3',\n",
    " 'B4',\n",
    " 'B5',\n",
    " 'C1',\n",
    " 'C2',\n",
    " 'C3',\n",
    " 'C4',\n",
    " 'C5',\n",
    " 'D1',\n",
    " 'D2',\n",
    " 'D3',\n",
    " 'D4',\n",
    " 'D5',\n",
    " 'E1',\n",
    " 'E2',\n",
    " 'E3',\n",
    " 'E4',\n",
    " 'E5',\n",
    " 'F1',\n",
    " 'F2',\n",
    " 'F3',\n",
    " 'F4',\n",
    " 'F5',\n",
    " 'G1',\n",
    " 'G2',\n",
    " 'G3',\n",
    " 'G4',\n",
    " 'G5',\n",
    " 'PURP:credit_card',\n",
    " 'PURP:car',\n",
    " 'PURP:small_business',\n",
    " 'PURP:other',\n",
    " 'PURP:wedding',\n",
    " 'PURP:debt_consolidation',\n",
    " 'PURP:home_improvement',\n",
    " 'PURP:major_purchase',\n",
    " 'PURP:medical',\n",
    " 'PURP:moving',\n",
    " 'PURP:vacation',\n",
    " 'PURP:house',\n",
    " 'PURP:renewable_energy',\n",
    " 'Defaulted',\n",
    " 'Closed',\n",
    " 'mos_from_origination',\n",
    " 'time_from_origination',\n",
    " 'time_from_origination_norm',\n",
    " 'ROI'\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# WRite file - if it exists, append to end without header.  If it doesn't already exist, write.\n",
    "# V 2.2 WRITES OUT A DIFFERENT FILENAME....\n",
    "write_url ='/Users/Glenn/Documents/LendingClub/LendingClub_CLEANED_v2.3.csv'\n",
    "\n",
    "import os\n",
    "# if file does not exist write header \n",
    "if not os.path.isfile(write_url):\n",
    "   lcd[write_columns].to_csv(write_url,header ='column_names')\n",
    "else: # else it exists so append without writing the header\n",
    "    lcd[write_columns].to_csv(write_url,mode = 'a',header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#   lcd2 is a dataframe which groups data by sub grade and issue month, year by average ROI - FOR CERRID PROJECT. \n",
    "lcd2 = lcd[lcd['Closed']==1].groupby([lcd.sub_grade,lcd.issue_MMYYYY]).ROI.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# WRite file of lcd2  - if it exists, append to end without header.  If it doesn't already exist, write.\n",
    "# This is data for the Cerrid project. \n",
    "\n",
    "write_url ='/Users/Glenn/Documents/LendingClub/LendingClub_CLEANED_Cerrid_v0.1.csv'\n",
    "\n",
    "import os\n",
    "# if file does not exist write header \n",
    "if not os.path.isfile(write_url):\n",
    "    lcd2.to_csv(write_url,header =write_columns2)\n",
    "else: # else it exists so append without writing the header\n",
    "    lcd2.to_csv(write_url,mode = 'a',header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
